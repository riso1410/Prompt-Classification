{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import statistics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from fastembed import TextEmbedding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from prompt_classifier.metrics import evaluate\n",
    "from prompt_classifier.modeling.dspy_gpt import GPT4oMini\n",
    "from prompt_classifier.modeling.fasttext import FastTextClassifier\n",
    "from prompt_classifier.modeling.nli_modernbert import ModernBERTNLI\n",
    "\n",
    "load_dotenv()\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "law_prompts = pd.read_csv('data/processed/law_prompts.csv', sep=';')\n",
    "general_prompts = pd.read_csv('data/processed/general_prompts.csv', sep=';')\n",
    "healthcare_prompts = pd.read_csv('data/processed/healthcare_prompts.csv', sep=';')\n",
    "finance_prompts = pd.read_csv('data/processed/finance_prompts.csv', sep=';')\n",
    "\n",
    "law_dataset = pd.concat([law_prompts, general_prompts]).sample(frac=1).reset_index(drop=True)\n",
    "healthcare_dataset = pd.concat([healthcare_prompts, general_prompts]).sample(frac=1).reset_index(drop=True)\n",
    "finance_dataset = pd.concat([finance_prompts, general_prompts]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "datasets = {'law': law_dataset, 'healthcare': healthcare_dataset, 'finance': finance_dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT baseline optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for domain, dataset in datasets.items():\n",
    "    train_data = dataset.sample(frac=0.00025)\n",
    "    test_data = dataset.drop(train_data.index).head(100)\n",
    "\n",
    "    gpt_classifier = GPT4oMini(api_key=os.getenv(\"OPENAI_API_KEY\"), proxy_url=os.getenv(\"PROXY_URL\"), model_name=\"gpt-4o-mini\",\n",
    "                            domain=domain, train_data=train_data, test_data=test_data)\n",
    "\n",
    "\n",
    "    gpt_classifier.optimize_model()\n",
    "\n",
    "    predictions, actuals, mean_latency = gpt_classifier.predict()\n",
    "\n",
    "    evaluate(predictions=predictions, true_labels=actuals, domain=domain, model_name=\"gpt4o-mini\", embed_model=\"ada-002\", cost=gpt_classifier.cost, latency=mean_latency)\n",
    "\n",
    "    gpt_classifier.save_model(f\"models/gpt-4o-mini-{domain}.json\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baai_embedding = TextEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "tf_idf_embedding = TfidfVectorizer()\n",
    "mini_embedding = TextEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "embedding_models = {'mini': mini_embedding, 'tf_idf': tf_idf_embedding, 'baai': baai_embedding}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m     test_embeds \u001b[38;5;241m=\u001b[39m embedding_model\u001b[38;5;241m.\u001b[39mtransform(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m     train_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(embedding_model\u001b[38;5;241m.\u001b[39membed(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     63\u001b[0m     test_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(embedding_model\u001b[38;5;241m.\u001b[39membed(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     64\u001b[0m     train_embeds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(train_embeds)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(train_embeds), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\risko\\miniconda3\\envs\\prompt-classification\\Lib\\site-packages\\fastembed\\text\\text_embedding.py:107\u001b[0m, in \u001b[0;36mTextEmbedding.embed\u001b[1;34m(self, documents, batch_size, parallel, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed\u001b[39m(\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     87\u001b[0m     documents: Union[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     91\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m    Encode a list of documents into list of embeddings.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    We use mean pooling with attention so that the model can handle variable-length inputs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m        List of embeddings, one per document\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39membed(documents, batch_size, parallel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\risko\\miniconda3\\envs\\prompt-classification\\Lib\\site-packages\\fastembed\\text\\onnx_embedding.py:276\u001b[0m, in \u001b[0;36mOnnxTextEmbedding.embed\u001b[1;34m(self, documents, batch_size, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed\u001b[39m(\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    256\u001b[0m     documents: Union[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    260\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m    261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    Encode a list of documents into list of embeddings.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m    We use mean pooling with attention so that the model can handle variable-length inputs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m        List of embeddings, one per document\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_documents(\n\u001b[0;32m    277\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m    278\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_dir),\n\u001b[0;32m    279\u001b[0m         documents\u001b[38;5;241m=\u001b[39mdocuments,\n\u001b[0;32m    280\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    281\u001b[0m         parallel\u001b[38;5;241m=\u001b[39mparallel,\n\u001b[0;32m    282\u001b[0m         providers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproviders,\n\u001b[0;32m    283\u001b[0m         cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda,\n\u001b[0;32m    284\u001b[0m         device_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids,\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    286\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\risko\\miniconda3\\envs\\prompt-classification\\Lib\\site-packages\\fastembed\\text\\onnx_text_model.py:117\u001b[0m, in \u001b[0;36mOnnxTextModel._embed_documents\u001b[1;34m(self, model_name, cache_dir, documents, batch_size, parallel, providers, cuda, device_ids, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_onnx_model()\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(documents, batch_size):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_onnx_output(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parallel \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\risko\\miniconda3\\envs\\prompt-classification\\Lib\\site-packages\\fastembed\\text\\onnx_text_model.py:84\u001b[0m, in \u001b[0;36mOnnxTextModel.onnx_embed\u001b[1;34m(self, documents, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m     onnx_input[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m     80\u001b[0m         [np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(e), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m input_ids], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64\n\u001b[0;32m     81\u001b[0m     )\n\u001b[0;32m     82\u001b[0m onnx_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_onnx_input(onnx_input, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 84\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mONNX_OUTPUT_NAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monnx_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m OnnxOutputContext(\n\u001b[0;32m     86\u001b[0m     model_output\u001b[38;5;241m=\u001b[39mmodel_output[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     87\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39monnx_input\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, attention_mask),\n\u001b[0;32m     88\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39monnx_input\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_ids),\n\u001b[0;32m     89\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\risko\\miniconda3\\envs\\prompt-classification\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:266\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    264\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for domain, dataset in datasets.items():\n",
    "    train_data = dataset.sample(frac=0.8).reset_index(drop=True)\n",
    "    test_data = dataset.drop(train_data.index).reset_index(drop=True)\n",
    "\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    prediction_times = []\n",
    "\n",
    "    # ModernBERT\n",
    "    # bert_classifier = ModernBERTNLI(domain=domain)\n",
    "    # for _, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "\n",
    "    #    start_time = time.perf_counter_ns()\n",
    "    #    prediction = bert_classifier.predict(row['prompt'])\n",
    "    #    end_time = time.perf_counter_ns()\n",
    "\n",
    "    #    actuals.append(row['label'])\n",
    "    #    prediction_times.append(end_time - start_time)\n",
    "\n",
    "    #    mean_prediction_time = statistics.mean(prediction_times)\n",
    "\n",
    "    #evaluate(predictions, actuals, domain, model_name='ModernBERT', embed_model='modernbert', latency=mean_prediction_time)\n",
    "\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    prediction_times = []\n",
    "\n",
    "    # fastText\n",
    "    fasttext_classifier = FastTextClassifier(train_data = train_data, test_data = test_data)\n",
    "    fasttext_classifier.train()\n",
    "\n",
    "    for _, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        text = str(row['prompt'])\n",
    "        query = text.replace('\\n', '')\n",
    "\n",
    "        start_time = time.perf_counter_ns()\n",
    "        prediction = fasttext_classifier.model.predict(query)\n",
    "        end_time = time.perf_counter_ns()\n",
    "        \n",
    "        prediction_times.append(end_time - start_time)\n",
    "\n",
    "        if prediction[0][0] == '__label__1':\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "\n",
    "        actuals.append(row['label'])\n",
    "\n",
    "    mean_prediction_time = statistics.mean(prediction_times)\n",
    "    evaluate(predictions, actuals, domain, model_name='fastText', embed_model='fasttext', latency=mean_prediction_time)\n",
    "\n",
    "    fasttext_classifier.model.save_model(f\"models/fastText_{domain}_fasttext.bin\")\n",
    "\n",
    "    # SVM and XGBoost with different embeddings\n",
    "    for model_name, embedding_model in embedding_models.items():\n",
    "\n",
    "        if model_name == 'tf_idf':\n",
    "            embedding_model.fit(train_data['prompt'])\n",
    "            train_embeds = embedding_model.transform(train_data['prompt'])\n",
    "            test_embeds = embedding_model.transform(test_data['prompt'])\n",
    "        else:\n",
    "            train_embeds = list(embedding_model.embed(train_data['prompt']))\n",
    "            test_embeds = list(embedding_model.embed(test_data['prompt']))\n",
    "            train_embeds = np.array(train_embeds).reshape(len(train_embeds), -1)\n",
    "            test_embeds = np.array(test_embeds).reshape(len(test_embeds), -1)\n",
    "        \n",
    "        \n",
    "        print(f\"Embedding model: {model_name}\")\n",
    "\n",
    "        actuals = []\n",
    "        predictions = []\n",
    "        prediction_times = []\n",
    "\n",
    "        # SVM\n",
    "        svm_classifier = SVC()\n",
    "        svm_classifier.fit(train_embeds, train_data['label'])\n",
    "\n",
    "\n",
    "        for i, row in test_data.iterrows():\n",
    "            start_time = time.perf_counter_ns()\n",
    "            prediction = svm_classifier.predict(test_embeds[i].reshape(1, -1))\n",
    "            end_time = time.perf_counter_ns()\n",
    "\n",
    "            prediction_times.append(end_time - start_time)\n",
    "            predictions.append(prediction[0])\n",
    "            actuals.append(row['label'])\n",
    "\n",
    "        mean_prediction_time = statistics.mean(prediction_times)\n",
    "        evaluate(predictions, actuals, domain, model_name='SVM', embed_model=model_name, latency=mean_prediction_time)\n",
    "        \n",
    "        with open(f\"models/SVM_{domain}_{model_name}.pkl\", 'wb') as f:\n",
    "            pickle.dump(svm_classifier, f)\n",
    "\n",
    "\n",
    "        actuals = []\n",
    "        predictions = []\n",
    "        prediction_times = []\n",
    "\n",
    "        # XGBoost\n",
    "        xgboost_classifier = XGBClassifier(n_jobs = -1)\n",
    "        xgboost_classifier.fit(train_embeds, train_data['label'])\n",
    "\n",
    "        for i, row in test_data.iterrows():\n",
    "            start_time = time.perf_counter_ns()\n",
    "            prediction = xgboost_classifier.predict(test_embeds[i].reshape(1, -1))\n",
    "            end_time = time.perf_counter_ns()\n",
    "            prediction_times.append(end_time - start_time)\n",
    "            predictions.append(prediction[0])\n",
    "            actuals.append(row['label'])\n",
    "\n",
    "        mean_prediction_time = statistics.mean(prediction_times)\n",
    "        evaluate(predictions, actuals, domain, model_name='XGBoost', embed_model=model_name, latency=mean_prediction_time)\n",
    "\n",
    "        xgboost_classifier.save_model(f\"models/XGBoost_{domain}_{model_name}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
