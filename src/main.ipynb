{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Models to add: wide MLP or another DL model (hugging face or custom)\n",
    "<hr>\n",
    "otestovat potom na llame mby \n",
    "<hr>\n",
    "vygenerovat cca 100 edge case dat\n",
    "\"What are the laws for ..bullshit..\", through validation\n",
    "<hr>\n",
    "lepsi open-domain dataset vytvorit, nejake general questions/prompts, moc odborne som zobral\n",
    " \n",
    "https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_classifier import LMTrainer, LMClassifier\n",
    "from svm_tfidf import SVMClassifier\n",
    "from fasttext_model import *\n",
    "from utilities import *\n",
    "import os\n",
    "import dotenv\n",
    "import requests\n",
    "import fasttext\n",
    "from fastembed import TextEmbedding\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords', download_dir=os.path.join(os.path.dirname('../.venv/'), 'nltk_data'))\n",
    "nltk.download('punkt_tab', download_dir=os.path.join(os.path.dirname('../.venv/'), 'nltk_data'))\n",
    "nltk.download('wordnet', download_dir=os.path.join(os.path.dirname('../.venv/'), 'nltk_data'))\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_path = \"../data/open_domain_data.csv\"\n",
    "specific_path = \"../data/specific_domain_data.csv\"\n",
    "\n",
    "train_size = 10_000\n",
    "test_size = 10_000\n",
    "val_size = 1000\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_data = pd.read_csv(open_path)\n",
    "specific_data = pd.read_csv(specific_path)\n",
    "\n",
    "open_data = open_data\n",
    "specific_data = specific_data\n",
    "\n",
    "merged_data = pd.concat([open_data, specific_data])\n",
    "\n",
    "shuffled_data = merged_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "shuffled_data['question'] = (\n",
    "    shuffled_data['question']\n",
    "    .apply(lambda x: re.sub(r'[^\\w\\s]', '', x.encode('utf-8').decode('utf-8').lower()))\n",
    ")\n",
    "\n",
    "train_data = shuffled_data[:train_size]\n",
    "val_data = shuffled_data[train_size:train_size + val_size]\n",
    "test_data = shuffled_data[train_size:train_size + test_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "available_models = get_models()\n",
    "if available_models:\n",
    "    print(\"Available models:\", available_models)\n",
    "else:\n",
    "    print(\"Failed to retrieve models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baai_embedding = TextEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "jina_embedding = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "miniLM_embedding = TextEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "proxy_url = os.getenv(\"PROXY_URL\")\n",
    "\n",
    "gpt_model = LMClassifier(api_key=api_key, proxy_url=proxy_url, domain='law', model_name='gpt-4o-mini', train_size=100, test_size=300)\n",
    "gpt_model.load_data(train_data=train_data, test_data=test_data)\n",
    "\n",
    "trainer = LMTrainer(gpt_model.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "true_labels = []\n",
    "total_cost = 0\n",
    "\n",
    "compiled_model = trainer.optimize_model()\n",
    "\n",
    "for example in tqdm(gpt_model.test_data):\n",
    "    prediction = trainer.optimized_model(prompt=example.prompt, domain=example.domain).label\n",
    "    predictions.append(prediction)\n",
    "    true_labels.append(example.label)\n",
    "    total_cost += calculate_prompt_cost(example.prompt+example.domain, completion=prediction, model_name=gpt_model.model_name)\n",
    "\n",
    "f1, accuracy, recall, precision = trainer.evaluate(predictions, true_labels)\n",
    "\n",
    "print(f\"Total cost is: {total_cost:.8f}$\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "trainer.save_model(f\"../models/{gpt_model.model_name}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM-TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocess_data(train_data)\n",
    "\n",
    "config = {\n",
    "    'C': 0.05,\n",
    "    'embedding_model': baai_embedding,\n",
    "}\n",
    "\n",
    "svm_classifier = SVMClassifier(config=config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_data['question'], test_data['question'], train_data['label'], test_data['label']\n",
    "\n",
    "X_train = list(config.get('embedding_model').embed(X_train))\n",
    "X_test = list(config.get('embedding_model').embed(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier.train(X_train, y_train)\n",
    "print(\"Training complete\")\n",
    "\n",
    "f1, accuracy, recall, precision = svm_classifier.evaluate(X_train, y_train)\n",
    "print(\"Overfitting check:\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "f1, accuracy, recall, precision = svm_classifier.evaluate(X_test, y_test)\n",
    "print(\"Final results:\")\n",
    "print(f\"F1 score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier.predict(\"If lepernauchs were recognized as healthcare providers, would their actions be covered under malpractice insurance laws?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "svm_classifier.save_model(model_path=f'../models/{svm_classifier.model_name}.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = FastText(train_data=train_data, test_data=test_data, val_data=val_data)\n",
    "\n",
    "train_file = \"../data/fasttext_train.txt\"\n",
    "test_file = \"../data/fasttext_test.txt\"\n",
    "val_file = \"../data/fasttext_val.txt\"\n",
    "\n",
    "fasttext_model.preprocess_data(train_path=train_file, test_path=test_file, val_path=val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.train_supervised(input=train_file, lr=0.001, epoch=100, autotuneValidationFile=val_file)\n",
    "\n",
    "print(\"Check overfitting:\")\n",
    "print_results(*ft_model.test(train_file))\n",
    "print()\n",
    "print(\"Final results:\")\n",
    "print_results(*ft_model.test(test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.predict(\"If lepernauchs were recognized as healthcare providers, would their actions be covered under malpractice insurance laws?\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save_model(f\"../models/{fasttext_model.model_name}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
